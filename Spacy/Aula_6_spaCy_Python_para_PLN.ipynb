{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Aula_6_spaCy_Python_para_PLN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Guimol/NLP-Projects/blob/main/Spacy/Aula_6_spaCy_Python_para_PLN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5Eou-fvY7awQ"
      },
      "source": [
        "# Instalação do Spacy\n",
        "\n",
        "Primeiro precisamos atualizar o spacy que já está instalado no colab.\n",
        "\n",
        "A versão que está disponível não dá suporte ao modelo de dados em portugues.\n",
        "\n",
        "https://spacy.io/usage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-BqxDKI1FVo4"
      },
      "source": [
        "pip install -U spacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RpafPx4v7qP2"
      },
      "source": [
        "**Depois de instalar precisamos baixar os pacotes complementares**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zS1JfXlBF42u"
      },
      "source": [
        "pip install -U spacy-lookups-data"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmiMoEVv7wMO"
      },
      "source": [
        "**E finalmente instalamos o modelo de língua disponibilizado pelo spaCy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6duQFrspGHvZ"
      },
      "source": [
        "!python -m spacy download pt_core_news_lg\n",
        "#!python -m spacy download pt_core_news_md\n",
        "#!python -m spacy download pt_core_news_sm"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9W9NiF0g742N"
      },
      "source": [
        "**Agora, o uso efetivo da biblioteca**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Y3BsZEUkI3E_"
      },
      "source": [
        "import spacy\n",
        "\n",
        "# Um texto de exemplo\n",
        "texto = \"Para políticos e infectologistas, a opção de Michelle de se 10 vacinar nos EUA, não no Brasil, 2021 é um absurdo e um desprezo ao SUS (Sistema Único de Saúde) e ao PNI (Programa Nacional de Imunizações).\"\n",
        "\n",
        "# Carregamos o modelo de língua que baixamos\n",
        "nlp = spacy.load(\"pt_core_news_lg\")\n",
        "\n",
        "# Usamos o modelo para analisar o nosso texto :)\n",
        "doc = nlp(texto)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "syWfeowp8KOG"
      },
      "source": [
        "**Usando a variável \"doc\" podemos acessar os tokens e as diversas análises feitas pelo spaCy**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j4dPg3ygJb1U"
      },
      "source": [
        "# geração da lista de tokens (tokenização)\n",
        "\n",
        "# Observe que essa estrutura pode ser convertida para a seguinte:\n",
        "# tokens = []\n",
        "# for token in tokens:\n",
        "#   tokens.append(token)\n",
        "\n",
        "tokens = [token for token in doc]\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bw_4X5aS8jXm"
      },
      "source": [
        "**Salvando na lista o texto dos tokens:** ***.orth_***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "obXc62cgK0IW"
      },
      "source": [
        "tokens = [token.orth_ for token in doc]\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KS_T4hTJ89VW"
      },
      "source": [
        "**Demais atributos**\n",
        "\n",
        "\n",
        "*   .is_alpha\n",
        "*   .is_digit\n",
        "*   .is_punct\n",
        "\n",
        "https://spacy.io/api/token#attributes\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-tOljq2VLUzW"
      },
      "source": [
        "alpha_tokens = [token.orth_ for token in doc if token.is_alpha]\n",
        "print(\"Alpha Tokens: %s \" % (alpha_tokens))\n",
        "\n",
        "digit_tokens = [token.orth_ for token in doc if token.is_digit]\n",
        "print(\"Digit Tokens: %s \" % (digit_tokens))\n",
        "\n",
        "punct_tokens = [token.orth_ for token in doc if token.is_punct]\n",
        "print(\"Punct Tokens: %s \" % (punct_tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FkaK9ex59dg-"
      },
      "source": [
        "**Vamos trabalhar com nosso corpus de teste :)**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Xs4veraNq5h"
      },
      "source": [
        "corpus = open('/content/drive/MyDrive/Codigos/BootcampPythonPLN/nltk/corpus_teste.txt').read()\n",
        "corpus"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RUXE-cGMOBqf"
      },
      "source": [
        "import spacy\n",
        "\n",
        "nlp = spacy.load(\"pt_core_news_lg\")\n",
        "doc = nlp(corpus)\n",
        "\n",
        "tokens = [token.orth_ for token in doc]\n",
        "tokens"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m_cHef15OYBM"
      },
      "source": [
        "alpha_tokens = [token.orth_ for token in doc if token.is_alpha]\n",
        "print(\"Alpha Tokens: %s \" % (alpha_tokens))\n",
        "\n",
        "digit_tokens = [token.orth_ for token in doc if token.is_digit]\n",
        "print(\"Digit Tokens: %s \" % (digit_tokens))\n",
        "\n",
        "punct_tokens = [token.orth_ for token in doc if token.is_punct]\n",
        "print(\"Punct Tokens: %s \" % (punct_tokens))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GhyxDky59k9m"
      },
      "source": [
        "**Lemmatização: *.lemma_***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DFlpqcyHOt-5"
      },
      "source": [
        "lemmas = [token.lemma_ for token in doc if token.pos_ == 'VERB']\n",
        "lemmas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lp7NrAUw9tWl"
      },
      "source": [
        "**Etiquetas morfosintáticas: *.pos_***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FJ6n-uiFP2DR"
      },
      "source": [
        "pos = [(token.orth_, token.pos_) for token in doc]\n",
        "pos"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SyQrAvKo92a3"
      },
      "source": [
        "**Análise morfosintática: *.morph***"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zq_mdqZyQW-f"
      },
      "source": [
        "morfologicas = [(token.orth_, token.morph) for token in doc]\n",
        "morfologicas"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Cy719af698_l"
      },
      "source": [
        "**Reconhecimento de Entidades Nomeadas**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YJVbQJL8SKr1"
      },
      "source": [
        "entidades_nomeadas = list(doc.ents)\n",
        "print(entidades_nomeadas)\n",
        "\n",
        "detalhes_entidades = [(entidade, entidade.label_) for entidade in doc.ents]\n",
        "detalhes_entidades"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uUVfKsRe-BfW"
      },
      "source": [
        "**Vamos visualizar as entidades!**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SNzLf69UUTgr"
      },
      "source": [
        "html = spacy.displacy.render(doc, style=\"ent\")\n",
        "output_path = open('entidades_nomadas.html', 'w', encoding=\"utf-8\")\n",
        "output_path.write(html)\n",
        "output_path.close()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "p9K86DrX-FiW"
      },
      "source": [
        "**Análise sintática de dependências**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LHbJhaafVISC"
      },
      "source": [
        "sintaxe = [(token.orth_, token.dep_) for token in doc]\n",
        "print(sintaxe)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pP7o939i-IWt"
      },
      "source": [
        "**Vamos visualizar a árvore de dependências**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1QvmBR5MVYg3"
      },
      "source": [
        "visualizar_sintaxe = spacy.displacy.render(doc, style='dep')\n",
        "output_path = open('analise_dependencia.svg', 'w', encoding=\"utf-8\")\n",
        "output_path.write(visualizar_sintaxe)\n",
        "output_path.close()"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}